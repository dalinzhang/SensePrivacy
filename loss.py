from keras import backend as K
from keras.regularizers import Regularizer
import numpy as np

def gram_matrix(x):
    assert K.ndim(x) == 3

    assert K.image_dim_ordering() == "tf"
    width, height, channels = K.int_shape(x)
    features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))

    gram = K.dot(features, K.transpose(features)) / (channels * width * height)
    return gram


class StyleReconstructionRegularizer(Regularizer):
    """ Johnson et al 2015 https://arxiv.org/abs/1603.08155 """

    def __init__(self, style_feature_target, weight=1.0):
        self.style_feature_target = K.variable(np.squeeze(style_feature_target, axis = 0))
        self.weight = weight
        self.uses_learning_phase = False
        super(StyleReconstructionRegularizer, self).__init__()

    def __call__(self, x):
        output = x.output[0] # Generated by network
        loss = self.weight * K.mean(K.sum(K.square(gram_matrix(output) - gram_matrix(self.style_feature_target))))
        return loss


class FeatureReconstructionRegularizer(Regularizer):
    """ Johnson et al 2015 https://arxiv.org/abs/1603.08155 """

    def __init__(self, weight=1.0):
        self.weight = weight
        self.uses_learning_phase = False
        super(FeatureReconstructionRegularizer, self).__init__()

    def __call__(self, x):
        assert K.image_dim_ordering() == "tf"

        generated = x.output[0] # Generated by network features
        content = x.output[1]

        width, height, channels = K.int_shape(generated)
        
        loss = self.weight * K.mean(K.sum(K.square(content - generated))) / (channels * height * width)
        return loss
